{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic timeseries models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the naive models are to form a benchmark for performance. This allows us to compare the performance of feature engineering, hyperparameter tuning, and model architecture against a set of references.\n",
    "\n",
    "\n",
    "### Test Harness: Walk forward validation\n",
    "A test rig is a naive implementation of the prediction model. In this notebook univariate and multivariate rigs are deployed as benchmarks for improvement in predictions.\n",
    "\n",
    "Naive univariate models are deployed using only the most recent data point in time to predict the next. I.e. t-1 = t. \n",
    "\n",
    "Multivariate models are deployed using all available feature vectors as predictors.  \n",
    "\n",
    "\n",
    "#### Classic Models\n",
    "- Univariate Naive\n",
    "- Multivariate Naive\n",
    "- Multivariate Moving Averages\n",
    "- Multivariate ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-0 h_0</th>\n",
       "      <th>t-1 h_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25833.0</td>\n",
       "      <td>27662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22113.0</td>\n",
       "      <td>25833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26810.0</td>\n",
       "      <td>22113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27578.0</td>\n",
       "      <td>26810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26897.0</td>\n",
       "      <td>27578.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t-0 h_0  t-1 h_0\n",
       "0  25833.0  27662.0\n",
       "1  22113.0  25833.0\n",
       "2  26810.0  22113.0\n",
       "3  27578.0  26810.0\n",
       "4  26897.0  27578.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the preprocessed data\n",
    "data = pd.read_csv('./data/processed/transformed_2016_2018.csv')\n",
    "\n",
    "#investigate features for h_0\n",
    "#y-hat is columns from t-0\n",
    "data[['t-0 h_0','t-1 h_0']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_X_Y_features(data, y_target='t-0', univariate=False):\n",
    "    \"\"\"\n",
    "    Function that takes in the preprocessed data and returns the Y and X datasets for univariate and multivariate test harnesses.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #if univariate is called, the function returns the current time step, and the previous time step.\n",
    "    if univariate:\n",
    "        y_target='t-0'\n",
    "        #select the column headers to build Y matrix\n",
    "        Y_cols = [col for col in data.columns if y_target == col.split()[0]]\n",
    "        \n",
    "        x_targets = 't-1'\n",
    "        #selects the columns headers to build feature vectors of X\n",
    "        X_cols = [col for col in data.columns if x_targets == col.split()[0]]\n",
    "    \n",
    "    #if not univariate then X and Y return the multivariate case with all features\n",
    "    else:\n",
    "        Y_cols = [col for col in data.columns if y_target == col.split()[0]]\n",
    "        \n",
    "        X_cols = [col for col in data.columns if y_target == col.split()[0]]\n",
    "        \n",
    "    #convert dataframe into numpy array\n",
    "    Y = np.array(data[Y_cols])\n",
    "    \n",
    "    X = np.array(data[X_cols])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1066, 24), (1066, 24))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_univar, Y_univar = set_X_Y_features(data, univariate=True)\n",
    "X_univar.shape, Y_univar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, Y, size):\n",
    "    \"\"\"\n",
    "    Function to split data into train and test sets.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_size = int(len(X) * size)\n",
    "    \n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    \n",
    "    Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (746, 24)\n",
      "Y_train shape: (746, 24)\n",
      "X_test shape: (320, 24)\n",
      "Y_test shape: (320, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train_univar, X_test_univar, Y_train_univar, Y_test_univar = split_train_test(X_univar, Y_univar, 0.70)\n",
    "\n",
    "print('X_train shape: {}'.format(X_train_univar.shape))\n",
    "print('Y_train shape: {}'.format(Y_train_univar.shape))\n",
    "print('X_test shape: {}'.format(X_test_univar.shape))\n",
    "print('Y_test shape: {}'.format(Y_test_univar.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "In multi-output problems errors are typically evaluated indivually per output period as opposed to aggregating. Aggregating can still give an indication of the general model performace. Using the indivdual errors however is useful to identify the time steps we are predicting well, versus those that are not.\n",
    "\n",
    "\n",
    "The base units of the problem are in MWh and having an error metric that is in these same units lets us make a direct comparison. Both Root Mean Squared Error and Mean Absolute Error are suitable for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(Y_hat_test, Y_test):\n",
    "    \n",
    "    columns = ['RMSE', 'MAE']\n",
    "    \n",
    "    error_list = []\n",
    "    \n",
    "    \n",
    "    #calculate the mse and mae for each hour in the Y_test and Prediction\n",
    "    for i in range(Y_hat_train.shape[1]):\n",
    "        error_list.append([\n",
    "            #calcualte the RMSE\n",
    "            np.sqrt(metrics.mean_squared_error(Y_hat_test[:,i], Y_test[:,i]).numpy()),\n",
    "            #calcualte the MAE\n",
    "            metrics.mean_absolute_error(Y_hat_test[:,i], Y_test[:,i]).numpy()\n",
    "        ])\n",
    "\n",
    "        \n",
    "    \n",
    "    errors = pd.DataFrame(error_list, columns=columns)\n",
    "    \n",
    "    return errors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Naive\n",
    "\n",
    "The univariate naive forecast uses the previous time step as the prediction for the next timestep. As this is a multi-step problem, the naive univariate uses all h0..h23 slices from t-1 as predictions for t.\n",
    "\n",
    "To calcualte the mean squared and absolute errors for this we will calculate the errors for each of h0...h23 for all time slices in the seires then sum these values. This gives an error for the full 24 hour ahead prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_univariate(X_train, X_test):\n",
    "    return X_train, X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MSE          MAE\n",
      "0   3.299129e+06  1305.699732\n",
      "1   2.786931e+06  1199.639410\n",
      "2   2.594002e+06  1157.549598\n",
      "3   2.534801e+06  1171.447721\n",
      "4   2.590720e+06  1205.084450\n",
      "5   3.106111e+06  1351.450402\n",
      "6   7.103553e+06  2026.420912\n",
      "7   1.883022e+07  3195.315013\n",
      "8   2.701522e+07  3798.644772\n",
      "9   2.436017e+07  3633.500000\n",
      "10  1.990717e+07  3303.415550\n",
      "11  1.772679e+07  3126.454424\n",
      "12  1.784318e+07  3145.319035\n",
      "13  1.673891e+07  3041.687668\n",
      "14  1.377310e+07  2740.873995\n",
      "15  1.564674e+07  2915.660858\n",
      "16  1.763742e+07  3101.571046\n",
      "17  1.856147e+07  3187.349866\n",
      "18  1.691876e+07  3034.004021\n",
      "19  1.507685e+07  2834.851206\n",
      "20  1.185563e+07  2501.213137\n",
      "21  8.241524e+06  2079.643432\n",
      "22  5.211170e+06  1603.162198\n",
      "23  3.572319e+06  1311.462466\n"
     ]
    }
   ],
   "source": [
    "Y_hat_train, Y_hat_test = naive_univariate(X_train_univar, X_test_univar)\n",
    "\n",
    "print(calculate_errors(Y_hat_train, Y_train_univar))\n",
    "#print(calculate_errors(Y_hat_test, Y_test_univar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 24)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_hat_train.shape[1])):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
