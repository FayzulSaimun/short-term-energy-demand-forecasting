{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic timeseries models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the naive models are to form a benchmark for performance. This allows us to compare the performance of feature engineering, hyperparameter tuning, and model architecture against a set of references.\n",
    "\n",
    "\n",
    "### Test Harness: Walk forward validation\n",
    "A test rig is a naive implementation of the prediction model. In this notebook univariate and multivariate rigs are deployed as benchmarks for improvement in predictions.\n",
    "\n",
    "Naive univariate models are deployed using only the most recent data point in time to predict the next. I.e. t-1 = t. \n",
    "\n",
    "Multivariate models are deployed using all available feature vectors as predictors.  \n",
    "\n",
    "\n",
    "#### Classic Models\n",
    "- Univariate Naive\n",
    "- Multivariate Naive\n",
    "- Multivariate Moving Averages\n",
    "- Multivariate ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-0 h_0</th>\n",
       "      <th>t-1 h_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25833.0</td>\n",
       "      <td>27662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22113.0</td>\n",
       "      <td>25833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26810.0</td>\n",
       "      <td>22113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27578.0</td>\n",
       "      <td>26810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26897.0</td>\n",
       "      <td>27578.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t-0 h_0  t-1 h_0\n",
       "0  25833.0  27662.0\n",
       "1  22113.0  25833.0\n",
       "2  26810.0  22113.0\n",
       "3  27578.0  26810.0\n",
       "4  26897.0  27578.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the preprocessed data\n",
    "data = pd.read_csv('./data/processed/transformed_2016_2018.csv')\n",
    "\n",
    "#investigate features for h_0\n",
    "#y-hat is columns from t-0\n",
    "data[['t-0 h_0','t-1 h_0']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_X_Y_features(data, y_target='t-0', univariate=False):\n",
    "    \"\"\"\n",
    "    Function that takes in the preprocessed data and returns the Y and X datasets for univariate and multivariate test harnesses.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #if univariate is called, the function returns the current time step, and the previous time step.\n",
    "    if univariate:\n",
    "        y_target='t-0'\n",
    "        #select the column headers to build Y matrix\n",
    "        Y_cols = [col for col in data.columns if y_target == col.split()[0]]\n",
    "        \n",
    "        x_targets = 't-1'\n",
    "        #selects the columns headers to build feature vectors of X\n",
    "        X_cols = [col for col in data.columns if x_targets == col.split()[0]]\n",
    "    \n",
    "    #if not univariate then X and Y return the multivariate case with all features\n",
    "    else:\n",
    "        Y_cols = [col for col in data.columns if y_target == col.split()[0]]\n",
    "        \n",
    "        X_cols = [col for col in data.columns if y_target == col.split()[0]]\n",
    "        \n",
    "    #convert dataframe into numpy array\n",
    "    Y = np.array(data[Y_cols])\n",
    "    \n",
    "    X = np.array(data[X_cols])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1066, 24), (1066, 24))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_univar, Y_univar = set_X_Y_features(data, univariate=True)\n",
    "X_univar.shape, Y_univar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, Y, size):\n",
    "    \"\"\"\n",
    "    Function to split data into train and test sets.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_size = int(len(X) * size)\n",
    "    \n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    \n",
    "    Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (746, 24)\n",
      "Y_train shape: (746, 24)\n",
      "X_test shape: (320, 24)\n",
      "Y_test shape: (320, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train_univar, X_test_univar, Y_train_univar, Y_test_univar = split_train_test(X_univar, Y_univar, 0.70)\n",
    "\n",
    "print('X_train shape: {}'.format(X_train_univar.shape))\n",
    "print('Y_train shape: {}'.format(Y_train_univar.shape))\n",
    "print('X_test shape: {}'.format(X_test_univar.shape))\n",
    "print('Y_test shape: {}'.format(Y_test_univar.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "In multi-output problems errors are typically evaluated indivually per output period as opposed to aggregating. Aggregating can still give an indication of the general model performace. Using the indivdual errors however is useful to identify the time steps we are predicting well, versus those that are not.\n",
    "\n",
    "\n",
    "The base units of the problem are in MWh and having an error metric that is in these same units lets us make a direct comparison. Both Root Mean Squared Error and Mean Absolute Error are suitable for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(Y_hat_test, Y_test, result_set):\n",
    "    \n",
    "    columns = [[result_set, result_set],['RMSE', 'MAE']]\n",
    "    \n",
    "    error_list = []\n",
    "    \n",
    "    \n",
    "    #calculate the mse and mae for each hour in the Y_test and Prediction\n",
    "    for i in range(Y_hat_train.shape[1]):\n",
    "        error_list.append([\n",
    "            #calcualte the RMSE\n",
    "            np.sqrt(metrics.mean_squared_error(Y_hat_test[:,i], Y_test[:,i]).numpy()),\n",
    "            #calcualte the MAE\n",
    "            metrics.mean_absolute_error(Y_hat_test[:,i], Y_test[:,i]).numpy()\n",
    "        ])\n",
    "\n",
    "    error_list.append([\n",
    "        np.mean(error_list[0]),\n",
    "        np.mean(error_list[1])\n",
    "    ])    \n",
    "    \n",
    "    \n",
    "    #set an index\n",
    "    index = ['h_' + str(x) for x in range(24)] + ['mean']\n",
    "    \n",
    "    \n",
    "    errors = pd.DataFrame(error_list, index=index, columns=columns)\n",
    "    \n",
    "    return errors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Naive\n",
    "\n",
    "The univariate naive forecast uses the previous time step as the prediction for the next timestep. As this is a multi-step problem, the naive univariate uses all h0..h23 slices from t-1 as predictions for t.\n",
    "\n",
    "To calcualte the mean squared and absolute errors for this we will calculate the errors for each of h0...h23 for all time slices in the seires then sum these values. This gives an error for the full 24 hour ahead prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_univariate(X_train, X_test):\n",
    "    return X_train, X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">naive_univariate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h_0</th>\n",
       "      <td>1816.350529</td>\n",
       "      <td>1305.699732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_1</th>\n",
       "      <td>1669.410475</td>\n",
       "      <td>1199.639410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_2</th>\n",
       "      <td>1610.590595</td>\n",
       "      <td>1157.549598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_3</th>\n",
       "      <td>1592.105834</td>\n",
       "      <td>1171.447721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_4</th>\n",
       "      <td>1609.571492</td>\n",
       "      <td>1205.084450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_5</th>\n",
       "      <td>1762.416266</td>\n",
       "      <td>1351.450402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_6</th>\n",
       "      <td>2665.249060</td>\n",
       "      <td>2026.420912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_7</th>\n",
       "      <td>4339.380526</td>\n",
       "      <td>3195.315013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_8</th>\n",
       "      <td>5197.617165</td>\n",
       "      <td>3798.644772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_9</th>\n",
       "      <td>4935.601956</td>\n",
       "      <td>3633.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_10</th>\n",
       "      <td>4461.745549</td>\n",
       "      <td>3303.415550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_11</th>\n",
       "      <td>4210.319728</td>\n",
       "      <td>3126.454424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_12</th>\n",
       "      <td>4224.119088</td>\n",
       "      <td>3145.319035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_13</th>\n",
       "      <td>4091.321078</td>\n",
       "      <td>3041.687668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_14</th>\n",
       "      <td>3711.213372</td>\n",
       "      <td>2740.873995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_15</th>\n",
       "      <td>3955.596205</td>\n",
       "      <td>2915.660858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_16</th>\n",
       "      <td>4199.692834</td>\n",
       "      <td>3101.571046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_17</th>\n",
       "      <td>4308.302075</td>\n",
       "      <td>3187.349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_18</th>\n",
       "      <td>4113.242359</td>\n",
       "      <td>3034.004021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_19</th>\n",
       "      <td>3882.891761</td>\n",
       "      <td>2834.851206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_20</th>\n",
       "      <td>3443.200266</td>\n",
       "      <td>2501.213137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_21</th>\n",
       "      <td>2870.805537</td>\n",
       "      <td>2079.643432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_22</th>\n",
       "      <td>2282.798827</td>\n",
       "      <td>1603.162198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_23</th>\n",
       "      <td>1890.057846</td>\n",
       "      <td>1311.462466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1561.025130</td>\n",
       "      <td>1434.524943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     naive_univariate             \n",
       "                 RMSE          MAE\n",
       "h_0       1816.350529  1305.699732\n",
       "h_1       1669.410475  1199.639410\n",
       "h_2       1610.590595  1157.549598\n",
       "h_3       1592.105834  1171.447721\n",
       "h_4       1609.571492  1205.084450\n",
       "h_5       1762.416266  1351.450402\n",
       "h_6       2665.249060  2026.420912\n",
       "h_7       4339.380526  3195.315013\n",
       "h_8       5197.617165  3798.644772\n",
       "h_9       4935.601956  3633.500000\n",
       "h_10      4461.745549  3303.415550\n",
       "h_11      4210.319728  3126.454424\n",
       "h_12      4224.119088  3145.319035\n",
       "h_13      4091.321078  3041.687668\n",
       "h_14      3711.213372  2740.873995\n",
       "h_15      3955.596205  2915.660858\n",
       "h_16      4199.692834  3101.571046\n",
       "h_17      4308.302075  3187.349866\n",
       "h_18      4113.242359  3034.004021\n",
       "h_19      3882.891761  2834.851206\n",
       "h_20      3443.200266  2501.213137\n",
       "h_21      2870.805537  2079.643432\n",
       "h_22      2282.798827  1603.162198\n",
       "h_23      1890.057846  1311.462466\n",
       "mean      1561.025130  1434.524943"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_train, Y_hat_test = naive_univariate(X_train_univar, X_test_univar)\n",
    "\n",
    "calculate_errors(Y_hat_train, Y_train_univar, 'naive_univariate')\n",
    "#print(calculate_errors(Y_hat_test, Y_test_univar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 24)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
