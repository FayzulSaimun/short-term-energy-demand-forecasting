{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Load Data Cleaning Explanation\n",
    "\n",
    "This notebook descrbes the process used to construct and clean the dataset.\n",
    "\n",
    "Data was aquired from entsoe Transparency Platform at the following [link](https://transparency.entsoe.eu/load-domain/r2/totalLoadR2/show?name=&defaultValue=false&viewType=TABLE&areaType=BZN&atch=false&dateTime.dateTime=09.08.2015+00:00|CET|DAY&biddingZone.values=CTY|10YES-REE------0!BZN|10YES-REE------0&dateTime.timezone=CET_CEST&dateTime.timezone_input=CET+(UTC+1)+/+CEST+(UTC+2)#) (2015 data). Data is downloadable on an annual basis. this workbook constructs an example dataset using the years 2016-2018. The same functions may be used to construct any number of years available from this source.\n",
    "\n",
    "Processes completed in the following functions:\n",
    "1. format_data\n",
    "    - renames the columns\n",
    "    - shortens the text identifier for times\n",
    "    - converts to a Datetime index\n",
    "2. combine_annual_data\n",
    "    - joins a dictionary if dataframes\n",
    "3. interpolate_nans\n",
    "    - fills the missing values using a linear interpolation method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/day-ahead-total-load-ES/'\n",
    "files = ['Total Load - Day Ahead _ Actual_2016.csv', 'Total Load - Day Ahead _ Actual_2017.csv', 'Total Load - Day Ahead _ Actual_2018.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in list of the datasets\n",
    "data_sets = [pd.read_csv(path+file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>day_forecast</th>\n",
       "      <th>actual_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2016 00:00</td>\n",
       "      <td>23273.0</td>\n",
       "      <td>22431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2016 01:00</td>\n",
       "      <td>22495.0</td>\n",
       "      <td>21632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2016 02:00</td>\n",
       "      <td>21272.0</td>\n",
       "      <td>20357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2016 03:00</td>\n",
       "      <td>20022.0</td>\n",
       "      <td>19152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2016 04:00</td>\n",
       "      <td>19148.0</td>\n",
       "      <td>18310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01.01.2016 05:00</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>18054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01.01.2016 06:00</td>\n",
       "      <td>18729.0</td>\n",
       "      <td>18234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01.01.2016 07:00</td>\n",
       "      <td>18647.0</td>\n",
       "      <td>18596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01.01.2016 08:00</td>\n",
       "      <td>18242.0</td>\n",
       "      <td>18541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01.01.2016 09:00</td>\n",
       "      <td>18164.0</td>\n",
       "      <td>18942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01.01.2016 10:00</td>\n",
       "      <td>19478.0</td>\n",
       "      <td>20484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01.01.2016 11:00</td>\n",
       "      <td>20619.0</td>\n",
       "      <td>21805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01.01.2016 12:00</td>\n",
       "      <td>21366.0</td>\n",
       "      <td>22607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01.01.2016 13:00</td>\n",
       "      <td>22335.0</td>\n",
       "      <td>23178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01.01.2016 14:00</td>\n",
       "      <td>22670.0</td>\n",
       "      <td>23265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01.01.2016 15:00</td>\n",
       "      <td>21309.0</td>\n",
       "      <td>22061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01.01.2016 16:00</td>\n",
       "      <td>20767.0</td>\n",
       "      <td>21481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01.01.2016 17:00</td>\n",
       "      <td>21194.0</td>\n",
       "      <td>21830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01.01.2016 18:00</td>\n",
       "      <td>23845.0</td>\n",
       "      <td>24291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01.01.2016 19:00</td>\n",
       "      <td>25055.0</td>\n",
       "      <td>25234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01.01.2016 20:00</td>\n",
       "      <td>25922.0</td>\n",
       "      <td>25881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01.01.2016 21:00</td>\n",
       "      <td>26372.0</td>\n",
       "      <td>26149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>01.01.2016 22:00</td>\n",
       "      <td>26374.0</td>\n",
       "      <td>25610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01.01.2016 23:00</td>\n",
       "      <td>24440.0</td>\n",
       "      <td>24000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time  day_forecast  actual_load\n",
       "0   01.01.2016 00:00       23273.0      22431.0\n",
       "1   01.01.2016 01:00       22495.0      21632.0\n",
       "2   01.01.2016 02:00       21272.0      20357.0\n",
       "3   01.01.2016 03:00       20022.0      19152.0\n",
       "4   01.01.2016 04:00       19148.0      18310.0\n",
       "5   01.01.2016 05:00       18750.0      18054.0\n",
       "6   01.01.2016 06:00       18729.0      18234.0\n",
       "7   01.01.2016 07:00       18647.0      18596.0\n",
       "8   01.01.2016 08:00       18242.0      18541.0\n",
       "9   01.01.2016 09:00       18164.0      18942.0\n",
       "10  01.01.2016 10:00       19478.0      20484.0\n",
       "11  01.01.2016 11:00       20619.0      21805.0\n",
       "12  01.01.2016 12:00       21366.0      22607.0\n",
       "13  01.01.2016 13:00       22335.0      23178.0\n",
       "14  01.01.2016 14:00       22670.0      23265.0\n",
       "15  01.01.2016 15:00       21309.0      22061.0\n",
       "16  01.01.2016 16:00       20767.0      21481.0\n",
       "17  01.01.2016 17:00       21194.0      21830.0\n",
       "18  01.01.2016 18:00       23845.0      24291.0\n",
       "19  01.01.2016 19:00       25055.0      25234.0\n",
       "20  01.01.2016 20:00       25922.0      25881.0\n",
       "21  01.01.2016 21:00       26372.0      26149.0\n",
       "22  01.01.2016 22:00       26374.0      25610.0\n",
       "23  01.01.2016 23:00       24440.0      24000.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inital look at the unprocessed data\n",
    "data_sets[0].head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "    '''\n",
    "    Input: A dataframe of Day Ahead Total Load, and Actual Load obtained from csv data obtained from the entsoe Transparency Platform.\n",
    "    \n",
    "    Descrption:\n",
    "    Input is a 3 column dataframe consisting of text time stamps with hourly frequency. \n",
    "    - Function formats the string in order to be formatted into a datetime.\n",
    "    - Appends a datetime index and drops the time strings\n",
    "    \n",
    "    Output: A 2 column dataframe with a DatetimeIndex\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #set column names to something simple\n",
    "    data.columns = ['time', 'day_forecast',\n",
    "       'actual_load']\n",
    "\n",
    "    #set the time to the first element in the time string. \n",
    "    #So 01.01.2018 00:00 - 01.01.2018 01:00 becomes 01.01.2018 00:00\n",
    "    data['time'] = data['time'].str.split('-').apply(lambda x: x[0]).str.strip()\n",
    "     \n",
    "    #set the time strings to datetime obejects and set index as date time\n",
    "    datetimes = pd.to_datetime(data['time'], format='%d-%m-%Y %H%M', errors='ignore')\n",
    "    data_ = data.set_index(pd.DatetimeIndex(datetimes))\n",
    "    \n",
    "    #remove extra time column with original string objects\n",
    "    data_time = data_[['day_forecast', 'actual_load']]\n",
    "    \n",
    "    return data_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2016', '2017', '2018']\n",
    "\n",
    "#create a dictionary of formatted pandas dataframes where key is each year\n",
    "format_sets = {year: format_data(data_set) for year,data_set in zip(years, data_sets)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_forecast</th>\n",
       "      <th>actual_load</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>23324.0</td>\n",
       "      <td>22779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>22688.0</td>\n",
       "      <td>22009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>21521.0</td>\n",
       "      <td>20589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>20294.0</td>\n",
       "      <td>19547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>19489.0</td>\n",
       "      <td>18871.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     day_forecast  actual_load\n",
       "time                                          \n",
       "2018-01-01 00:00:00       23324.0      22779.0\n",
       "2018-01-01 01:00:00       22688.0      22009.0\n",
       "2018-01-01 02:00:00       21521.0      20589.0\n",
       "2018-01-01 03:00:00       20294.0      19547.0\n",
       "2018-01-01 04:00:00       19489.0      18871.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the formatted data\n",
    "format_sets['2018'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data into single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_annual_data(dictionary):\n",
    "    \"\"\"\n",
    "    Input: a dictionary of dataframes.\n",
    "    \n",
    "    Output: a single dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    all_data_list = []\n",
    "    \n",
    "    for key in dictionary.keys():\n",
    "        all_data_list.append(dictionary[key])\n",
    "        \n",
    "    data_all_years = pd.concat(all_data_list)\n",
    "    \n",
    "    return data_all_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine into one single dataframe\n",
    "data = combine_annual_data(clean_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean NANs\n",
    "\n",
    "This data will be used for predicting day ahead energy demand. In dealing with nan values it is important not to change the structure of the data. \n",
    "\n",
    "Two ways this can occur:\n",
    "   1. dropping values changes number of observations in a day. number of daily observations per day needs to line up with the days before and after.\n",
    "   2. filling missing values with a single value (i.e. series mean value) is not representiative of the temporal nature of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 26307 entries, 2016-01-01 00:00:00 to 2018-12-31 23:00:00\n",
      "Data columns (total 2 columns):\n",
      "day_forecast    26304 non-null float64\n",
      "actual_load     26295 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 616.6 KB\n"
     ]
    }
   ],
   "source": [
    "#check for nans in the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(day_forecast     3\n",
       " actual_load     12\n",
       " dtype: int64, 26307)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the total nans in each column and the total length of the data.\n",
    "data.isnull().sum(), len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 3 and 12 nan values respectively in a dataset of length 26307. This is very clean data.\n",
    "\n",
    "Can savfely imput the data with a linear interpolation function without changing the structure of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatetimeIndex(['2016-03-27 02:00:00', '2016-04-25 05:00:00',\n",
       "                '2016-04-25 07:00:00', '2016-07-09 22:00:00',\n",
       "                '2016-09-28 09:00:00', '2016-05-10 23:00:00',\n",
       "                '2017-03-26 02:00:00', '2017-11-14 12:00:00',\n",
       "                '2017-11-14 19:00:00', '2018-03-25 02:00:00',\n",
       "                '2018-06-11 18:00:00', '2018-07-11 09:00:00'],\n",
       "               dtype='datetime64[ns]', name='time', freq=None),\n",
       " DatetimeIndex(['2016-03-27 02:00:00', '2017-03-26 02:00:00',\n",
       "                '2018-03-25 02:00:00'],\n",
       "               dtype='datetime64[ns]', name='time', freq=None))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#isolate the row indexes that with Nans\n",
    "#use this to check the repalce_nans function works\n",
    "nan_load = data[data['actual_load'].isnull()==True].index\n",
    "nan_forecast = data[data['day_forecast'].isnull()==True].index\n",
    "(nan_load, nan_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nans(data, columns):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - data --- a dataframe of timeseries data\n",
    "    - columns --- a list of column header names\n",
    "    \n",
    "    Process:\n",
    "    Applies linear interpolation to fill the missing entries per column\n",
    "    \n",
    "    output: a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in columns:\n",
    "        data[col] = data[col].interpolate(method='linear')\n",
    "    \n",
    "    return data\n",
    "\n",
    "# data['day_forecast'] = data['day_forecast'].interpolate(method='linear')\n",
    "# data['actual_load'] = data['actual_load'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_forecast</th>\n",
       "      <th>actual_load</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-27 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-25 05:00:00</th>\n",
       "      <td>21471.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-25 07:00:00</th>\n",
       "      <td>27635.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-09 22:00:00</th>\n",
       "      <td>34985.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-28 09:00:00</th>\n",
       "      <td>31072.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-10 23:00:00</th>\n",
       "      <td>26641.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-26 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14 12:00:00</th>\n",
       "      <td>33805.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14 19:00:00</th>\n",
       "      <td>35592.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-25 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 18:00:00</th>\n",
       "      <td>34752.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-11 09:00:00</th>\n",
       "      <td>33938.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     day_forecast  actual_load\n",
       "time                                          \n",
       "2016-03-27 02:00:00           NaN          NaN\n",
       "2016-04-25 05:00:00       21471.0          NaN\n",
       "2016-04-25 07:00:00       27635.0          NaN\n",
       "2016-07-09 22:00:00       34985.0          NaN\n",
       "2016-09-28 09:00:00       31072.0          NaN\n",
       "2016-05-10 23:00:00       26641.0          NaN\n",
       "2017-03-26 02:00:00           NaN          NaN\n",
       "2017-11-14 12:00:00       33805.0          NaN\n",
       "2017-11-14 19:00:00       35592.0          NaN\n",
       "2018-03-25 02:00:00           NaN          NaN\n",
       "2018-06-11 18:00:00       34752.0          NaN\n",
       "2018-07-11 09:00:00       33938.0          NaN"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the function works\n",
    "data[data['actual_load'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_forecast</th>\n",
       "      <th>actual_load</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [day_forecast, actual_load]\n",
       "Index: []"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of the column headers\n",
    "columns = data.columns[1:]\n",
    "\n",
    "data = interpolate_nans(data, columns)\n",
    "\n",
    "data[data['actual_load'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-03-27 02:00:00       21388.0      21626.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-04-25 05:00:00       21471.0      22528.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-04-25 07:00:00       27635.0      26928.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-07-09 22:00:00       34985.0      34263.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-09-28 09:00:00       31072.0      31597.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-05-10 23:00:00       26641.0      27519.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2017-03-26 02:00:00       22504.0      22967.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2017-11-14 12:00:00       33805.0      33970.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2017-11-14 19:00:00       35592.0      35709.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2018-03-25 02:00:00       23295.0      23999.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2018-06-11 18:00:00       34752.0      34186.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2018-07-11 09:00:00       33938.0      33492.5\n"
     ]
    }
   ],
   "source": [
    "#take a look at the interpreted values and see how they compare to the values around them.\n",
    "for t in nan_load:\n",
    "    print(data[str(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the prepared data as csv\n",
    "data.to_csv(path + 'load_forecast_2016_2018.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
